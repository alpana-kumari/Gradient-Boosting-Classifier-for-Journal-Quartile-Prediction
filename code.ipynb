{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Objective:**\n",
    "- To create a predictive model that accurately classifies scientific journals into their respective quartiles (Q1, Q2, Q3, Q4, NQ) by handling missing SJR values using regression imputation and leveraging a Gradient Boosting Classifier for classification. Users can specify their field of study, and the model will filter and classify the journals accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C://Users//Alpana//Desktop//clg files//fall sem 2024-25//machine learning//dataset.xlsx\"\n",
    "data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (29165, 24)\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count per column:\n",
      "Rank                        0\n",
      "Sourceid                    0\n",
      "Title                       0\n",
      "Type                        0\n",
      "Issn                        0\n",
      "SJR                       210\n",
      "SJR Best Quartile           0\n",
      "H index                     0\n",
      "Total Docs. (2023)          0\n",
      "Total Docs. (3years)        0\n",
      "Total Refs.                 0\n",
      "Total Cites (3years)        0\n",
      "Citable Docs. (3years)      0\n",
      "Cites / Doc. (2years)       0\n",
      "Ref. / Doc.                 0\n",
      "%Female                     0\n",
      "Overton                     0\n",
      "SDG                         0\n",
      "Country                     0\n",
      "Region                      0\n",
      "Publisher                 407\n",
      "Coverage                    0\n",
      "Categories                  0\n",
      "Areas                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find and display the count of missing values in each column\n",
    "missing_values_count = data.isnull().sum()\n",
    "print(\"Missing values count per column:\")\n",
    "print(missing_values_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "- Since our dataset contains 29,165 instances, and we have 210 rows with missing SJR values, we will use an advanced imputation technique to fill these missing values. \n",
    "- Given the context and the potential relationships between SJR and other features, we will use a regression model for imputation. \n",
    "This method will help us predict the missing SJR values based on other available features in the dataset.\n",
    "________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Context**\n",
    "    - Scientific journals are categorized into quartiles (Q1, Q2, Q3, Q4, NQ) based on their impact and influence within a specific field of study. The SCImago Journal Rank (SJR) is a critical bibliometric indicator that reflects the average number of weighted citations received by a journal's articles over a particular period. However, journals often have missing SJR values like in our dataset we have 210 missing values, making it challenging to accurately predict their quartile rankings. \n",
    "\n",
    "    - This project aims to develop a machine learning model to predict the quartile category of journals, considering the specific field of study and various available bibliometric factors, even in the presence of missing SJR values.\n",
    "\n",
    "    **Bibliometric indicators** are quantitative measures used to evaluate the impact, productivity, and quality of academic research publications and their influence within the scientific community. These indicators are commonly used in academic and research institutions for various purposes, including assessing the performance of researchers, journals, institutions, and research programs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **OUR Bibliometric indicators**\n",
    " \n",
    " \n",
    "SJR Best Quartile\n",
    "- The best quartile ranking of a journal based on its SJR (SCImago Journal Rank) score.\n",
    "- Q1, Q2, Q3, Q4, NQ (not quartile ranked).\n",
    "\n",
    "SJR (SCImago Journal Rank)\n",
    "- The average number of weighted citations received in a particular year by articles published in the journal during the three preceding years.\n",
    "- Data Type: Real number.\n",
    "\n",
    "H Index\n",
    "- The number of articles (h) in a journal that have received at least h citations over the entire period.\n",
    "- Data Type: Integer.\n",
    "\n",
    "Total Docs. (2017)\n",
    "- The total number of documents published by the journal in 2017.\n",
    "- Data Type: Real number.\n",
    "\n",
    "Total Docs. (3 years)\n",
    "- The total number of documents published by the journal over the previous three years (2014-2016).\n",
    "- Data Type: Integer.\n",
    "\n",
    "Total Refs.\n",
    "- The total number of references included in the journal's articles published in 2017.\n",
    "- Data Type: Real number.\n",
    "\n",
    "Total Cites (3 years)\n",
    "- The total number of citations received in 2017 by articles published in the journal during the previous three years (2014-2016).\n",
    "- Data Type: Integer.\n",
    "\n",
    "Citable Docs. (3 years)\n",
    "- The number of citable documents (articles, reviews, conference papers) published in the journal over the previous three years (2014-2016).\n",
    "- Data Type: Integer.\n",
    "\n",
    "Cites/Doc. (2 years)\n",
    "- The average number of citations per document in a two-year period.\n",
    "- Data Type: Real number.\n",
    "\n",
    "Ref./Doc.\n",
    "- The average number of references per document published in the journal in 2017.\n",
    "- Data Type: Real number.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**FILLING MISSING VALUES USING REGRESSION MODEL**\n",
    "___________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (29165, 24)\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SJR Best Quartile\n",
       "Q1    8702\n",
       "Q2    7295\n",
       "Q3    6674\n",
       "Q4    6069\n",
       "-      425\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SJR Best Quartile'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"-\" with \"NQ\"\n",
    "data['SJR Best Quartile'] = data['SJR Best Quartile'].replace(\"-\", \"NQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SJR Best Quartile\n",
       "Q1    8702\n",
       "Q2    7295\n",
       "Q3    6674\n",
       "Q4    6069\n",
       "NQ     425\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SJR Best Quartile'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_columns = ['SJR', 'H Index', 'Total Docs. (2017)', 'Total Docs. (3 years)', 'Total Refs.', 'Total Cites (3 years)', 'Citable Docs. (3 years)', 'Cites/Doc. (2 years)', 'Ref./Doc.']\n",
    "categorical_columns = ['Rank', 'Title', 'Issn', 'Coverage', 'Categories', 'Areas']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and separate the rows with missing SJR\n",
    "missing_sjr_data = data[data['SJR'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target for the rows with complete SJR values\n",
    "complete_data = data.dropna(subset=['SJR'])\n",
    "X_train = complete_data.drop(columns=['SJR', 'SJR Best Quartile'] + categorical_columns)\n",
    "y_train = complete_data['SJR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for the rows with missing SJR\n",
    "X_test = missing_sjr_data.drop(columns=['SJR', 'SJR Best Quartile'] + categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target for the rows with complete SJR values\n",
    "complete_data = data.dropna(subset=['SJR'])\n",
    "X_train = complete_data.drop(columns=['SJR', 'Rank', 'Title', 'Issn', 'Coverage', 'Categories', 'Areas'])\n",
    "y_train = complete_data['SJR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for the rows with missing SJR\n",
    "X_test = missing_sjr_data.drop(columns=['SJR', 'Rank', 'Title', 'Issn', 'Coverage', 'Categories', 'Areas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- due to one hot encoding - testing and training data may have different feature columns \n",
    "- Alignment is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align columns in the test set to match the training set\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the regression model\n",
    "regressor = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training columns:\n",
      "Index(['Sourceid', 'H index', 'Total Docs. (2023)', 'Total Docs. (3years)',\n",
      "       'Total Refs.', 'Total Cites (3years)', 'Citable Docs. (3years)',\n",
      "       'Cites / Doc. (2years)', 'Ref. / Doc.', '%Female',\n",
      "       ...\n",
      "       'Publisher_shi you yu tian ran qi di zhi bian ji bu',\n",
      "       'Publisher_shu xue xue bao bian ji bu',\n",
      "       'Publisher_slamic Republic of Iran Medical Council',\n",
      "       'Publisher_suburban eV', 'Publisher_universitat de Trieste',\n",
      "       'Publisher_universitatea de vest',\n",
      "       'Publisher_xian dai sui dao ji shu bian ji bu',\n",
      "       'Publisher_ying yong guang xue bian ji bu',\n",
      "       'Publisher_zhong guo shi pin xue bao bian ji bu',\n",
      "       'Publisher_zhong guo xue xi chong bing fang zhi za zhi she'],\n",
      "      dtype='object', length=8249)\n",
      "Test columns:\n",
      "Index(['Sourceid', 'H index', 'Total Docs. (2023)', 'Total Docs. (3years)',\n",
      "       'Total Refs.', 'Total Cites (3years)', 'Citable Docs. (3years)',\n",
      "       'Cites / Doc. (2years)', 'Ref. / Doc.', '%Female',\n",
      "       ...\n",
      "       'Publisher_shi you yu tian ran qi di zhi bian ji bu',\n",
      "       'Publisher_shu xue xue bao bian ji bu',\n",
      "       'Publisher_slamic Republic of Iran Medical Council',\n",
      "       'Publisher_suburban eV', 'Publisher_universitat de Trieste',\n",
      "       'Publisher_universitatea de vest',\n",
      "       'Publisher_xian dai sui dao ji shu bian ji bu',\n",
      "       'Publisher_ying yong guang xue bian ji bu',\n",
      "       'Publisher_zhong guo shi pin xue bao bian ji bu',\n",
      "       'Publisher_zhong guo xue xi chong bing fang zhi za zhi she'],\n",
      "      dtype='object', length=8249)\n"
     ]
    }
   ],
   "source": [
    "# Check the columns in both X_train and X_test\n",
    "print(\"Training columns:\")\n",
    "print(X_train.columns)\n",
    "print(\"Test columns:\")\n",
    "print(X_test.columns)\n",
    "\n",
    "# Align columns in X_test to match X_train\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict missing SJR values\n",
    "predicted_sjr = regressor.predict(X_test)\n",
    "data.loc[data['SJR'].isna(), 'SJR'] = predicted_sjr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count per column:\n",
      "Rank                        0\n",
      "Sourceid                    0\n",
      "Title                       0\n",
      "Type                        0\n",
      "Issn                        0\n",
      "SJR                         0\n",
      "SJR Best Quartile           0\n",
      "H index                     0\n",
      "Total Docs. (2023)          0\n",
      "Total Docs. (3years)        0\n",
      "Total Refs.                 0\n",
      "Total Cites (3years)        0\n",
      "Citable Docs. (3years)      0\n",
      "Cites / Doc. (2years)       0\n",
      "Ref. / Doc.                 0\n",
      "%Female                     0\n",
      "Overton                     0\n",
      "SDG                         0\n",
      "Country                     0\n",
      "Region                      0\n",
      "Publisher                 407\n",
      "Coverage                    0\n",
      "Categories                  0\n",
      "Areas                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find and display the count of missing values in each column\n",
    "missing_values_count = data.isnull().sum()\n",
    "print(\"Missing values count per column:\")\n",
    "print(missing_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter data based on user input and train the classifier\n",
    "def train_and_evaluate_model(field_of_study):\n",
    "    filtered_data = data[data['Areas'].str.contains(field_of_study, case=False, na=False)].copy()\n",
    "    \n",
    "    if filtered_data.empty:\n",
    "        print(f\"No data available for the specified field of study: {field_of_study}\")\n",
    "        return\n",
    "    \n",
    "    # Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    filtered_data.loc[:, 'SJR Best Quartile'] = label_encoder.fit_transform(filtered_data['SJR Best Quartile'])\n",
    "    \n",
    "    # Define features and target for classification\n",
    "    X = filtered_data.drop(columns=['Rank', 'Title', 'Issn', 'Coverage', 'Categories', 'Areas', 'SJR Best Quartile'])\n",
    "    y = filtered_data['SJR Best Quartile']\n",
    "    \n",
    "    # Ensure target variable is categorical\n",
    "    y = y.astype('int')\n",
    "    \n",
    "    # One-hot encode categorical variables\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the Gradient Boosting Classifier\n",
    "    classifier = GradientBoostingClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and evaluate the model\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Classification report for field of study: {field_of_study}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Combined Areas:\n",
    "def get_unique_areas(data):\n",
    "    areas = data['Areas'].str.split(';')\n",
    "    unique_areas = set()\n",
    "    for area_list in areas:\n",
    "        if area_list:\n",
    "            unique_areas.update([area.strip() for area in area_list])\n",
    "    return unique_areas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available fields of study:\n",
      "Multidisciplinary\n",
      "Materials Science\n",
      "Neuroscience\n",
      "Nursing\n",
      "Mathematics\n",
      "Pharmacology, Toxicology and Pharmaceutics\n",
      "Psychology\n",
      "Decision Sciences\n",
      "Computer Science\n",
      "Environmental Science\n",
      "Veterinary\n",
      "Social Sciences\n",
      "Health Professions\n",
      "Arts and Humanities\n",
      "Chemistry\n",
      "Biochemistry, Genetics and Molecular Biology\n",
      "Physics and Astronomy\n",
      "Economics, Econometrics and Finance\n",
      "Earth and Planetary Sciences\n",
      "Business, Management and Accounting\n",
      "Energy\n",
      "Chemical Engineering\n",
      "Dentistry\n",
      "Medicine\n",
      "Immunology and Microbiology\n",
      "Agricultural and Biological Sciences\n",
      "Engineering\n"
     ]
    }
   ],
   "source": [
    "# Show available fields of study   \n",
    "unique_fields_of_study = get_unique_areas(data)\n",
    "print(\"Available fields of study:\")\n",
    "for field in unique_fields_of_study:\n",
    "    print(field)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for field of study: Chemical Engineering\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NQ       1.00      0.50      0.67         2\n",
      "          Q1       0.88      0.98      0.93        47\n",
      "          Q2       0.85      0.83      0.84        42\n",
      "          Q3       0.96      0.84      0.90        31\n",
      "          Q4       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.90       142\n",
      "   macro avg       0.93      0.83      0.86       142\n",
      "weighted avg       0.90      0.90      0.90       142\n",
      "\n",
      "Accuracy: 90.14%\n",
      "Total accuracy of the model for the specified field of study 'Chemical Engineering' is: 90.14%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "field_of_study = input(\"Enter the field of study: \")\n",
    "total_accuracy = train_and_evaluate_model(field_of_study)\n",
    "print(f\"Total accuracy of the model for the specified field of study '{field_of_study}' is: {total_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
